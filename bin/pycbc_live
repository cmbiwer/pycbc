#!/usr/bin/env python
import multiprocessing, argparse, numpy, pycbc, logging, cProfile
from pycbc import version, waveform, types, filter as pfilter, scheme, psd as pypsd, noise, vetoes
from pycbc.types import MultiDetOptionAction

from pycbc.fft import ifft
from pycbc.filter import correlate
from pycbc import strain

parser = argparse.ArgumentParser()
parser.add_argument('--verbose', action='store_true')
parser.add_argument('--version', action='version', version=version.git_verbose_msg)
parser.add_argument('--bank-file', help="Template bank xml file")
parser.add_argument('--low-frequency-cutoff', help="low frequency cutoff", type=int)
parser.add_argument('--sample-rate', help="output sample rate", type=int)
parser.add_argument('--chisq-bins', help="Number of chisq bins")
parser.add_argument('--analysis-chunk', help="Amount of data to produce triggers in a  block", type=int)
parser.add_argument('--snr-threshold', type=float)
parser.add_argument('--channel-name', action=MultiDetOptionAction, nargs='+')
parser.add_argument('--frame-src', action=MultiDetOptionAction, nargs='+')
parser.add_argument('--start-time', type=int, default=0)

parser.add_argument('--approximant')
scheme.insert_processing_option_group(parser)

args = parser.parse_args()
scheme.verify_processing_options(args, parser)
pycbc.init_logging(args.verbose)

ctx = scheme.from_cli(args)

sr = args.sample_rate
flow = args.low_frequency_cutoff


psd_pad = 4
valid_pad = args.analysis_chunk
total_pad = psd_pad * 2 + valid_pad

bank = waveform.LiveFilterBank(args.bank_file, flow, sr, total_pad, approximant=args.approximant)

waveforms = list(bank)
lengths = numpy.array([1.0 / waveform.delta_f for waveform in waveforms])

ifos = args.channel_name.keys()

data_reader = {}
for ifo in ifos:
    data_reader[ifo] = pycbc.strain.StrainBuffer([args.frame_src[ifo]], 
                                    '%s:%s' % (ifo, args.channel_name[ifo]),
                                    args.start_time, 
                                    max_buffer=lengths.max(),
                                    sample_rate=args.sample_rate)

out = {}
cout = {}
for bl in set(lengths):
    bl = int(bl)
    df = 1.0 / bl
    tlen = bl * sr
    out[bl] = types.zeros(tlen, dtype=numpy.complex64)   
    cout[bl] = out[bl] * 1

pr = cProfile.Profile()
pr.enable()

# get more data

power_chisq = vetoes.SingleDetPowerChisq(args.chisq_bins, None)


with ctx:
    # prime pump for testing
    for i in range(35):
        for ifo in ifos:
            data_reader[ifo].advance(valid_pad)
    for ifo in ifos:
        data_reader[ifo].recalculate_psd()

    for i in range(10):
        logging.info('Conditioning Data')
        for ifo in ifos:
            data_reader[ifo].advance(valid_pad)
            data_reader[ifo].recalculate_psd()     
 
        logging.info('Start Filtering')
        for i, htilde in enumerate(waveforms):

            for ifo in ifos:
                bl = int(1.0 / htilde.delta_f)
        
                stilde = data_reader[ifo].overwhitened_data(htilde.delta_f)
                psd = stilde.psd    

                norm = 4.0 * htilde.delta_f / (htilde.sigmasq(psd) ** 0.5)
                correlate(htilde, stilde, cout[bl][0:len(stilde)])
                ifft(cout[bl], out[bl])
                cout[bl].fill(0)

                # Find peaks
                olen = len(out[bl])
                m, l = out[bl][olen - sr * (total_pad):olen - sr * psd_pad].abs_max_loc()

                # If nothing is above threshold we can exit this template
                if m * norm < args.snr_threshold:
                    continue

                # calculate chisq
                idx = olen - total_pad * sr + l
                snrv = numpy.array([out[bl][idx]])
                chisq, dof = power_chisq.values(cout[bl], snrv, norm, psd, [idx], htilde)
                chisq /= dof
                #print snrv * norm, chisq

            # Calculate coincidences
        logging.info('End Filtering')

# cluster coincs over bank, calculate FAR

# send report if above threshold


pr.disable()
pr.dump_stats('log')


#print lengths.mean()
#print lengths.min()
#print lengths.max()
#print lengths.sum() * sr / 1024 / 1024 * 4
#print "LATENCY MIN", 4 + psd_pad + valid_pad
